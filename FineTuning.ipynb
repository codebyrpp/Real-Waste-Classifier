{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNLE5dUy8aZQdLugv9XlV8U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codebyrpp/Real-Waste-Classifier/blob/feat%2Fwaste-classifier/FineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IocGdieQR6sp"
      },
      "outputs": [],
      "source": [
        "#using pretrained ResNet-50 and EfficientNet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, classification_report\n",
        "import seaborn as sns\n",
        "import random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_S5C6oUoVwn7",
        "outputId": "c7c9e595-0da3-4631-9994-ecd030521eb5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sam-single/realwaste.git\n",
        "data_dir = \"realwaste/RealWaste\"\n",
        "\n",
        "# Transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "dataset = datasets.ImageFolder(data_dir, transform=val_test_transforms)\n",
        "\n",
        "# Split dataset (70/15/15)\n",
        "total_size = len(dataset)\n",
        "train_size = int(0.7 * total_size)\n",
        "val_size = int(0.15 * total_size)\n",
        "test_size = total_size - train_size - val_size\n",
        "\n",
        "indices = list(range(total_size))\n",
        "random.seed(42)\n",
        "random.shuffle(indices)\n",
        "\n",
        "train_indices = indices[:train_size]\n",
        "val_indices = indices[train_size:train_size+val_size]\n",
        "test_indices = indices[train_size+val_size:]\n",
        "\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "val_dataset = Subset(dataset, val_indices)\n",
        "test_dataset = Subset(dataset, test_indices)\n",
        "\n",
        "# Apply training transforms\n",
        "train_dataset.dataset.transform = train_transforms\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "classes = dataset.classes\n",
        "print(\"Classes:\", classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DESdruQV0dx",
        "outputId": "220cd3a8-ed0f-4cf3-956c-229d514139df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'realwaste'...\n",
            "remote: Enumerating objects: 4782, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 4782 (delta 4), reused 8 (delta 1), pack-reused 4764 (from 1)\u001b[K\n",
            "Receiving objects: 100% (4782/4782), 655.92 MiB | 24.04 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n",
            "Updating files: 100% (4754/4754), done.\n",
            "Classes: ['Cardboard', 'Food Organics', 'Glass', 'Metal', 'Miscellaneous Trash', 'Paper', 'Plastic', 'Textile Trash', 'Vegetation']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load ResNet-50\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Freeze early layers (optional, for faster training)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace final layer for your dataset\n",
        "num_classes = len(classes)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0S-W5cvnWYmp",
        "outputId": "cd6d428b-56c2-4460-e47a-ee55608d12ae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 107MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)  # Only train final layer initially"
      ],
      "metadata": {
        "id": "pSn2Kq1nWl56"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, optimizer, criterion, epochs=10):\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accs, val_accs = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        correct, total, running_loss = 0, 0, 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = 100 * correct / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        correct, total, val_loss = 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_acc = 100 * correct / total\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
        "              f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs\n"
      ],
      "metadata": {
        "id": "FraQtbZlWs3n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, val_losses, train_accs, val_accs = train_model(model, train_loader, val_loader, optimizer, criterion, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5LF_h5kWzG4",
        "outputId": "376b3c10-0b78-40d0-af57-ed5ad7c952ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Train Loss: 1.4002, Val Loss: 1.0201, Train Acc: 53.46%, Val Acc: 67.84%\n",
            "Epoch 2/20, Train Loss: 0.9129, Val Loss: 0.8711, Train Acc: 69.39%, Val Acc: 70.65%\n",
            "Epoch 3/20, Train Loss: 0.8220, Val Loss: 0.8333, Train Acc: 72.10%, Val Acc: 69.52%\n",
            "Epoch 4/20, Train Loss: 0.7420, Val Loss: 0.7102, Train Acc: 74.35%, Val Acc: 75.70%\n",
            "Epoch 5/20, Train Loss: 0.6972, Val Loss: 0.7499, Train Acc: 76.28%, Val Acc: 73.03%\n",
            "Epoch 6/20, Train Loss: 0.6768, Val Loss: 0.6975, Train Acc: 76.85%, Val Acc: 75.84%\n",
            "Epoch 7/20, Train Loss: 0.6580, Val Loss: 0.7052, Train Acc: 76.91%, Val Acc: 75.98%\n",
            "Epoch 8/20, Train Loss: 0.6228, Val Loss: 0.6644, Train Acc: 78.11%, Val Acc: 76.83%\n",
            "Epoch 9/20, Train Loss: 0.6146, Val Loss: 0.6333, Train Acc: 78.95%, Val Acc: 76.54%\n",
            "Epoch 10/20, Train Loss: 0.5942, Val Loss: 0.6372, Train Acc: 79.22%, Val Acc: 77.11%\n",
            "Epoch 11/20, Train Loss: 0.5806, Val Loss: 0.6495, Train Acc: 79.56%, Val Acc: 76.40%\n",
            "Epoch 12/20, Train Loss: 0.5614, Val Loss: 0.6273, Train Acc: 80.67%, Val Acc: 78.09%\n",
            "Epoch 13/20, Train Loss: 0.5689, Val Loss: 0.6187, Train Acc: 79.49%, Val Acc: 79.49%\n",
            "Epoch 14/20, Train Loss: 0.5435, Val Loss: 0.6144, Train Acc: 80.58%, Val Acc: 79.07%\n",
            "Epoch 15/20, Train Loss: 0.5360, Val Loss: 0.6345, Train Acc: 81.18%, Val Acc: 77.67%\n",
            "Epoch 16/20, Train Loss: 0.5235, Val Loss: 0.6072, Train Acc: 81.69%, Val Acc: 76.40%\n",
            "Epoch 17/20, Train Loss: 0.5185, Val Loss: 0.6237, Train Acc: 81.36%, Val Acc: 76.40%\n",
            "Epoch 18/20, Train Loss: 0.5038, Val Loss: 0.6065, Train Acc: 82.02%, Val Acc: 77.11%\n",
            "Epoch 19/20, Train Loss: 0.4946, Val Loss: 0.6406, Train Acc: 82.08%, Val Acc: 76.83%\n",
            "Epoch 20/20, Train Loss: 0.5023, Val Loss: 0.6070, Train Acc: 82.41%, Val Acc: 77.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.layer4.parameters():  # unfreeze last block\n",
        "    param.requires_grad = True\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-5)  # smaller LR for fine-tuning\n",
        "train_losses, val_losses, train_accs, val_accs = train_model(model, train_loader, val_loader, optimizer, criterion, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEpm1pcqcur2",
        "outputId": "d12d1ea8-e096-41b1-bc8c-c1b96142d962"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Train Loss: 0.4403, Val Loss: 0.5287, Train Acc: 84.34%, Val Acc: 81.18%\n",
            "Epoch 2/5, Train Loss: 0.3545, Val Loss: 0.4850, Train Acc: 88.21%, Val Acc: 83.85%\n",
            "Epoch 3/5, Train Loss: 0.2947, Val Loss: 0.4276, Train Acc: 90.14%, Val Acc: 84.27%\n",
            "Epoch 4/5, Train Loss: 0.2543, Val Loss: 0.4625, Train Acc: 92.00%, Val Acc: 83.85%\n",
            "Epoch 5/5, Train Loss: 0.2006, Val Loss: 0.3973, Train Acc: 94.05%, Val Acc: 85.53%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8k1Nk9HKdGpw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}